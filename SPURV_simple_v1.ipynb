{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version_info)\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import configparser\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import itertools\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Cropping2D, Dropout, Conv2D, concatenate, TimeDistributed, CuDNNLSTM, LSTM, BatchNormalization\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import mean_squared_error, binary_crossentropy\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# import pydotplus\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlc_one_hot = { 1: [1,0,0], 2:[0,1,0], 3:[0,0,1] }\n",
    "#hlc_one_hot = { 1: [1,0,0,0], 2:[0,1,0,0], 3:[0,0,1,0], 4:[0,0,0,1]}\n",
    "\n",
    "def flatten_list(items_list):\n",
    "    \"\"\" Removes the episode dimension from a list of data points \"\"\"\n",
    "    ret = []\n",
    "    for items in items_list:\n",
    "        for item in items:\n",
    "            ret.append(item)        \n",
    "    return ret      \n",
    "\n",
    "# Custom loss function \n",
    "def weighted_mse(y_true, y_pred, weight_mask):\n",
    "    \"\"\" \n",
    "    Custom loss fucntion, different weigted loss to steer/throttle/brake \n",
    "    Used when all outputs is evaluated by same loss function \n",
    "    \"\"\"\n",
    "    return K.mean(K.square(y_pred - y_true)*weight_mask, axis=-1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Custom loss function, RMSE \"\"\"\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "    \n",
    "def steer_loss():\n",
    "    \"\"\" Loss function for steering, RMSE \"\"\"\n",
    "    def custom(y_true, y_pred):\n",
    "        return root_mean_squared_error(y_true, y_pred)\n",
    "    return custom\n",
    "\n",
    "def get_hlc_one_hot(hlc):\n",
    "    \"\"\" One-hot encode HLC values \"\"\"\n",
    "    return hlc_one_hot[hlc]\n",
    "\n",
    "def sine_encode(angle):\n",
    "    \"\"\" Encode steering angle as sine wave \"\"\"\n",
    "    angle_max = 1\n",
    "    N = 10\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(1,N+1,1):\n",
    "        Y = np.sin(((2*np.pi*(i-1))/(N-1))-((angle*np.pi)/(2*angle_max)))\n",
    "        ret.append(Y)\n",
    "    \n",
    "    return np.array(ret)\n",
    "\n",
    "def create_input_dict():\n",
    "    return {\n",
    "        \"forward_imgs\": [],\n",
    "        \"hlcs\" : [],\n",
    "    }\n",
    "\n",
    "def create_target_dict():\n",
    "    return {\n",
    "        \"steer\" : [],\n",
    "        \"throttle\": [],\n",
    "    }\n",
    "\n",
    "def split_dict(dictionary, split_pos):\n",
    "    \"\"\" Split data into training and validation \"\"\"\n",
    "    train_dict = {}\n",
    "    val_dict = {}\n",
    "    \n",
    "    for key in dictionary:\n",
    "        train_dict[key] = dictionary[key][:split_pos]\n",
    "        val_dict[key] = dictionary[key][split_pos:]\n",
    "    \n",
    "    return train_dict, val_dict\n",
    "\"\"\"\n",
    "def adjust_hlcs(hlcs, info_signals):\n",
    "    Randomly adjust HLC backwards, \n",
    "    such that the HLC data is given before the car is in the intersection \n",
    "    \n",
    "    # Iterate over all episodes \n",
    "    for e in range(len(hlcs)): \n",
    "        active_change_hlc = None\n",
    "        changed = 0\n",
    "        adjust_num = random.randint(20, 40)\n",
    "        # Iterate over all hlcs in episode \n",
    "        for i in range(len(hlcs[e])-2,-1, -1):\n",
    "            next_hlc = np.argmax(hlcs[e][i+1]) + 1 \n",
    "            current_hlc = np.argmax(hlcs[e][i]) +1 \n",
    "            if active_change_hlc == False:\n",
    "                active_change_hlc = None\n",
    "                continue\n",
    "\n",
    "            if active_change_hlc is None:\n",
    "                if next_hlc == 1 or next_hlc == 2 or next_hlc == 3:                     \n",
    "                    if current_hlc == 4: \n",
    "                        active_change_hlc = hlcs[e][i+1]\n",
    "            if active_change_hlc is not None: \n",
    "                hlcs[e][i] = active_change_hlc\n",
    "                if info_signals[e][i][2] != 0: \n",
    "                    changed += 1\n",
    "                if changed == adjust_num:\n",
    "                    active_change_hlc = False\n",
    "                    changed = 0 \n",
    "    return hlcs \n",
    "\"\"\"\n",
    "#### BALANCING DATA - Helper functions #### \n",
    "def get_hlc_dist_label(hlc): \n",
    "    \" Get distributions of HLC in data \"\n",
    "    if hlc == 1: \n",
    "        return \"left\"\n",
    "    elif hlc == 2:\n",
    "        return \"right\"\n",
    "    elif hlc == 3:\n",
    "        return \"straight\"\n",
    "    \n",
    "def get_speed_dist_label(speed): \n",
    "    \"\"\" Get distributions of speed in data \"\"\"\n",
    "\n",
    "    if speed < 0.001: \n",
    "        return \"low_speed\"\n",
    "    else: \n",
    "        return \"high_speed\"\n",
    "    \n",
    "def get_speed_limit_dist_label(speed_limit): \n",
    "    \"\"\" Get distributions of speed limits in data \"\"\"\n",
    "\n",
    "    speed_limit = round(speed_limit, 1)\n",
    "    if speed_limit == 0.3: \n",
    "        return \"30km/h\"\n",
    "    elif speed_limit == 0.6: \n",
    "        return \"60km/h\"\n",
    "    elif speed_limit == 0.9: \n",
    "        return \"90km/h\"\n",
    "    \n",
    "def get_percentage_dist(dist): \n",
    "    \"\"\" Get distribution of data in percentage \"\"\"\n",
    "    N = dist[\"traffic_light\"][\"red\"] + dist[\"traffic_light\"][\"green\"]\n",
    "    for dist_key in dist:\n",
    "        for key, dist_val in dist[dist_key].items(): \n",
    "            dist[dist_key][key] = dist_val/N \n",
    "    return dist \n",
    "\n",
    "def get_drop_num(tot_num, num, keep_fraction):\n",
    "    \"\"\" Calculates how many datasamples one should drop to get the right amount of data samples \"\"\"\n",
    "    return int((num - keep_fraction*tot_num)/(1-keep_fraction))\n",
    "\n",
    "\n",
    "def shuffle_data(inputs_flat, targets_flat):\n",
    "    # Shuffle\n",
    "    indices = np.arange(len(inputs_flat[\"forward_imgs\"]))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for key in inputs_flat: \n",
    "        inputs_flat[key] = np.array(inputs_flat[key])[indices]\n",
    "        \n",
    "    for key in targets_flat: \n",
    "        targets_flat[key] = np.array(targets_flat[key])[indices]\n",
    "\n",
    "    return inputs_flat, targets_flat\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentations \n",
    "- Lightness\n",
    "- Hue \n",
    "- Gaussian Blur\n",
    "- Shadows \n",
    "- Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(lab_img): \n",
    "    bgr_img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2BGR) \n",
    "    rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB) \n",
    "    plt.imshow(rgb_img)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def generate_shadow_coordinates(imshape, no_of_shadows=1):\n",
    "    vertices_list=[]\n",
    "    for index in range(no_of_shadows):\n",
    "        vertex=[]\n",
    "        for dimensions in range(np.random.randint(3,15)): ## Dimensionality of the shadow polygon\n",
    "            vertex.append(( imshape[1]*np.random.uniform(),imshape[0]//3+imshape[0]*np.random.uniform()))\n",
    "        vertices = np.array([vertex], dtype=np.int32) ## single shadow vertices \n",
    "        vertices_list.append(vertices)\n",
    "    return vertices_list ## List of shadow vertices\n",
    "\n",
    "def generate_random_lines(imshape,slant,drop_length):    \n",
    "    drops=[]    \n",
    "    for i in range(1500): \n",
    "        ## If You want heavy rain, try increasing this        \n",
    "        if slant<0:            \n",
    "            x= np.random.randint(slant,imshape[1])        \n",
    "        else:            \n",
    "            x= np.random.randint(0,imshape[1]-slant)        \n",
    "        y= np.random.randint(0,imshape[0]-drop_length)        \n",
    "        \n",
    "        drops.append((x,y))    \n",
    "    return drops \n",
    "\n",
    "def change_light(bgr_img, light_coeff, debug=False):\n",
    "    \n",
    "    lab_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB) \n",
    "    lab_img[:,:,0] = np.minimum(lab_img[:,:,0]*light_coeff, 255)\n",
    "    if debug: \n",
    "        show_image(lab_img)\n",
    "    \n",
    "    return np.array(lab_img, dtype = np.uint8)\n",
    "    \n",
    "def change_hue(bgr_img, hue_coeff, debug=False): \n",
    "    hsv_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2HSV) \n",
    "    hsv_img[:,:,0] = (hsv_img[:,:,0]*hue_coeff)%255   \n",
    "    \n",
    "    bgr_img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR) \n",
    "    lab_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    if debug: \n",
    "        show_image(lab_img)\n",
    "    return np.array(lab_img, dtype = np.uint8)\n",
    "           \n",
    "\n",
    "def add_rain(bgr_img, debug=False):     \n",
    "    bgr_img = np.copy(bgr_img)\n",
    "    imshape = bgr_img.shape    \n",
    "    slant_extreme = 10   \n",
    "    slant= 0 #np.random.randint(-slant_extreme,slant_extreme)     \n",
    "    drop_length=7\n",
    "    drop_width=1   \n",
    "    drop_color=(200,200,200) ## a shade of gray   \n",
    "    rain_drops= generate_random_lines(imshape,slant,drop_length)        \n",
    "    for rain_drop in rain_drops:        \n",
    "        cv2.line(bgr_img,(rain_drop[0],rain_drop[1]),(rain_drop[0]+slant,rain_drop[1]+drop_length),drop_color,drop_width)    \n",
    "    bgr_img= cv2.blur(bgr_img,(3,3)) ## rainy view are blurry         \n",
    "    \n",
    "    lab_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    if debug: \n",
    "        show_image(lab_img)\n",
    "    \n",
    "    return np.array(lab_img, dtype = np.uint8)\n",
    "\n",
    "    \n",
    "\n",
    "def add_shadow(bgr_img,no_of_shadows=1, debug=False):\n",
    "    lab_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB) \n",
    "    mask = np.zeros_like(lab_img) \n",
    "    img_shape = lab_img.shape\n",
    "    vertices_list= generate_shadow_coordinates(img_shape, no_of_shadows) #3 getting list of shadow vertices\n",
    "    for vertices in vertices_list: \n",
    "        cv2.fillPoly(mask, vertices, 255) ## adding all shadow polygons on empty mask, single 255 denotes only red channel\n",
    "    \n",
    "    lab_img[:,:,0][mask[:,:,0]==255] = lab_img[:,:,0][mask[:,:,0]==255]*0.2   ## if red channel is hot, image's \"Lightness\" channel's brightness is lowered \n",
    "    \n",
    "    if debug: \n",
    "        show_image(lab_img)\n",
    "    \n",
    "    return np.array(lab_img, dtype = np.uint8)\n",
    "\n",
    "def gaussian_blur(bgr_img, amount=3, debug=False):\n",
    "    bgr_img = cv2.GaussianBlur(bgr_img,(amount,amount),0)\n",
    "    lab_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB)\n",
    "    if debug: \n",
    "        show_image(lab_img)\n",
    "    \n",
    "    return np.array(lab_img, dtype = np.uint8)\n",
    "\n",
    "print_aug = False  \n",
    "\n",
    "if print_aug: \n",
    "    test_path = \"dataset/etron/Town04/ClientAP/cars_no_rain_noise5/2019-06-18_18-23-14/imgs/forward_center_rgb_00000082.png\"\n",
    "    #test_path = \"dataset/etron/Town04/ClientAP/cars_no_rain_noise5/2019-06-18_18-17-14/imgs/forward_right_rgb_00000062.png\"\n",
    "    bgr_img = cv2.imread(test_path)\n",
    "    print(\"Original image\")\n",
    "    show_image(cv2.cvtColor(bgr_img, cv2.COLOR_BGR2LAB))\n",
    "\n",
    "    print(\"Gaussian\")\n",
    "    blur_img = gaussian_blur(bgr_img, amount=11, debug=True)\n",
    "\n",
    "    print(\"Rain\")\n",
    "    rain_img = add_rain(bgr_img, debug=True)\n",
    "\n",
    "    print(\"Shadows\")\n",
    "    shadow_img = add_shadow(bgr_img, debug=True)\n",
    "\n",
    "    print(\"Lightness\")\n",
    "    light_img = change_light(bgr_img, light_range[0], debug=True)\n",
    "\n",
    "    print(\"Hue\")\n",
    "    hue_img = change_hue(bgr_img, hue_range[1], debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load driving logs\n",
    "- Loads data from all csv file in a lits of folders \n",
    "- Stores the data in a input dictionary and a target dictionary \n",
    "- Normalizes and coverts data to correct format \n",
    "- Does not use side cameraes for lane change data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_driving_logs(dataset_folders, steering_correction):\n",
    "    \"\"\" \n",
    "    input: \n",
    "        dataset_folders: list of paths to folders to load data from \n",
    "        steering_correction: float, adjusts steering angles of forward facing side cameras \n",
    "        \n",
    "    Loads data from all csv file in a lits of folders \n",
    "    Stores the data in a input dictionary and a target dictionary \n",
    "    Normalizes and coverts data to correct format \n",
    "    Does not use side cameraes for lane change data\n",
    "    \n",
    "    return: \n",
    "        inputs: dictionary of all input data (image paths, info signals, HLCs, control signals)\n",
    "        targets: dictionary of all target data (steer, throttle, brake)\n",
    "    \"\"\"\n",
    "    img_paths_center = []\n",
    "    \n",
    "    \n",
    "    inputs = create_input_dict()\n",
    "    \n",
    "    targets = create_target_dict()\n",
    "    # Loads data \n",
    "    for folder in dataset_folders:\n",
    "        folder_path = Path(\"dataset\") / folder\n",
    "        for episode in glob(str(folder_path / \"*\")):\n",
    "            \n",
    "            \n",
    "            temp_forward = {\"center\": [], \"left\": [], \"right\": []}\n",
    "            temp_hlcs =  {\"center\": [], \"left\": [], \"right\": []}\n",
    "\n",
    "            temp_steer =  {\"center\": [], \"left\": [], \"right\": []}\n",
    "            temp_throttle = {\"center\": [], \"left\": [], \"right\": []}\n",
    "                \n",
    "            episode_path = Path(episode)\n",
    "\n",
    "            df = pd.read_csv(str(episode_path / \"driving_log.csv\"))\n",
    "            for index, row in df.iterrows():\n",
    "                if index == 0: \n",
    "                    continue \n",
    "                                                        \n",
    "                steer = row[\"angle\"]\n",
    "                throttle = row[\"speed\"]\n",
    "                                \n",
    "                hlc = row[\"high_level_command\"]\n",
    "                if hlc == 0 or hlc == -1:\n",
    "                    hlc = 4\n",
    "                hlc = get_hlc_one_hot(hlc)\n",
    "                \n",
    "                temp_forward[\"center\"].append(str(episode_path / row[\"image_path\"]))              \n",
    "                temp_steer[\"center\"].append(steer)\n",
    "                temp_throttle[\"center\"].append(throttle)\n",
    "                temp_hlcs[\"center\"].append(hlc)\n",
    "                                \n",
    "                    \n",
    "            inputs[\"forward_imgs\"].append(temp_forward[\"center\"])\n",
    "                        \n",
    "            inputs[\"hlcs\"].append(temp_hlcs[\"center\"])\n",
    "                        \n",
    "            targets[\"steer\"].append(temp_steer[\"center\"])\n",
    "            \n",
    "            targets[\"throttle\"].append(temp_throttle[\"center\"])\n",
    "\n",
    "\n",
    "    print(\"Done, {:d} episode(s) loaded.\".format(len(inputs[\"forward_imgs\"])))\n",
    "\n",
    "    return(inputs, targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dist, title=\"\"):\n",
    "    \"\"\" Plots distribution of HLC, speed and traffic lights \"\"\"\n",
    "    print(\"Plotting...\")\n",
    "    tot_num = 0\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,6))\n",
    "\n",
    "    # HLC\n",
    "    labels =[\"Left\", \"Right\", \"Straight\"]\n",
    "    sizes = [dist[\"hlc\"][\"left\"], dist[\"hlc\"][\"right\"], dist[\"hlc\"][\"straight\"]]\n",
    "    \n",
    "    ax1 = fig.add_subplot(1,4,1)\n",
    "    wedges, texts, autotexts = ax1.pie(sizes, autopct='%.1f%%')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "\n",
    "    ax1.set_title(\"Distrubution of HLC\")\n",
    "    ax1.legend(wedges,labels, loc=\"best\")\n",
    "    ax1.axis('equal')\n",
    "    \n",
    "\n",
    "    # Speed\n",
    "    labels =[\"Low Speed\", \"High Speed\"]\n",
    "    sizes = [dist[\"speed\"][\"low\"], dist[\"speed\"][\"high\"]]\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,4,2)\n",
    "    wedges, texts, autotexts = ax2.pie(sizes, autopct='%.1f%%')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    ax2.set_title(\"Distrubution of speed\")\n",
    "    ax2.legend(wedges,labels, loc=\"best\")\n",
    "    ax2.axis('equal')\n",
    "\n",
    "    # Steering\n",
    "    labels =[\"Left\", \"Straight\", \"Right\"]\n",
    "    sizes = [dist[\"steering\"][\"left\"], dist[\"steering\"][\"straight\"], dist[\"steering\"][\"right\"]]\n",
    "    \n",
    "    ax2 = fig.add_subplot(1,4,2)\n",
    "    wedges, texts, autotexts = ax2.pie(sizes, autopct='%.1f%%')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    ax2.set_title(\"Distrubution of speed\")\n",
    "    ax2.legend(wedges,labels, loc=\"best\")\n",
    "    ax2.axis('equal')\n",
    "    \n",
    "\n",
    "    fig.suptitle(title + \": \" + str(tot_num) + \" sequences\", fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data \n",
    "\n",
    "- Get distribution of HLC, speed, speed limit, and traffic lights \n",
    "- Balance data for LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(inputs, targets): \n",
    "    \"\"\" \n",
    "        input:\n",
    "            inputs: dictionary of input data \n",
    "            targets: dictionary of result data\n",
    "                \n",
    "        return: \n",
    "            dist: dictionary of distributions for HLC, speed, angle \n",
    "    \"\"\"\n",
    "    dist = {\n",
    "        \"hlc\": {\n",
    "            \"left\": 0,\n",
    "            \"right\": 0, \n",
    "            \"straight\": 0,\n",
    "        },\n",
    "        \"steering\": {\n",
    "            \"left\": 0, # More than 20 deg left\n",
    "            \"right\": 0, # More than 20 deg right\n",
    "            \"straight\": 0 # Between left and right\n",
    "        },\n",
    "        \"speed\": {\n",
    "            \"high\": 0, #More than 0.5m/s\n",
    "            \"low\": 0 #Less than 0.5 m/s\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    print(\"getting dist\", inputs, targets)\n",
    "    # HLC distribution\n",
    "    for hlcs in inputs[\"hlcs\"]: \n",
    "        \n",
    "        # Iterate over all HLC in sequence \n",
    "        for hlc in hlcs: \n",
    "            hlc_value = np.argmax(hlc) + 1\n",
    "            if hlc_value == 0:\n",
    "                dist[\"hlc\"][\"left\"] += 1\n",
    "            elif hlc_value == 1:\n",
    "                dist[\"hlc\"][\"straight\"] += 1\n",
    "            elif hlc_value == 2:\n",
    "                dist[\"hlc\"][\"right\"] += 1\n",
    "\n",
    "            \n",
    "    # Speed distribution \n",
    "    for speed in targets[\"throttle\"]: \n",
    "        if speed > 0.5:\n",
    "            dist[\"speed\"][\"high\"] +=1 \n",
    "        else: \n",
    "            dist[\"speed\"][\"low\"] +=1 \n",
    "            \n",
    "    # Steering distribution \n",
    "    for angle in targets[\"steer\"]: \n",
    "        if angle < -0.2:\n",
    "            dist[\"steering\"][\"left\"] +=1 \n",
    "        elif angle > 0.2:\n",
    "            dist[\"steering\"][\"right\"] += 1\n",
    "        else: \n",
    "            dist[\"steering\"][\"straight\"] +=1         \n",
    "        \n",
    "    return dist   \n",
    "    \n",
    "\n",
    "def balance_steering_angle(inputs, targets, dist, target_straight_fraction): \n",
    "    \"\"\" Balance steer angle such that target fraction is correct \"\"\"\n",
    "    \n",
    "    tot_num = 0 \n",
    "    \n",
    "    for hlc_key in dist[\"steering\"]:\n",
    "        tot_num += dist[\"steering\"][hlc_key] \n",
    "    \n",
    "    dist_straight_num = dist[\"steering\"][\"straight\"]\n",
    "\n",
    "    target_straight_num = tot_num * target_straight_fraction\n",
    "    \n",
    "    number_to_drop = dist_straight_num - target_straight_num  \n",
    "    \n",
    "    inputs_bal = create_input_dict()\n",
    "    targets_bal = create_target_dict() \n",
    "    \n",
    "    dropped = 0\n",
    "    \n",
    "    for i in range(len(inputs[\"hlcs\"])): \n",
    "        if dropped >= number_to_drop:\n",
    "            break;\n",
    "            \n",
    "        angle = targets[\"steering\"][i]\n",
    "\n",
    "        if angle < 0.2 and angle > -0.2:\n",
    "            dropped +=1\n",
    "            continue\n",
    "        \n",
    "        # Keep \n",
    "        for key in inputs_bal: \n",
    "            inputs_bal[key].append(inputs[key][i])\n",
    "        for key in targets_bal: \n",
    "            targets_bal[key].append(targets[key][i])\n",
    "\n",
    "\n",
    "    return inputs_bal, targets_bal \n",
    "\n",
    "\n",
    "def balance_data_lstm(inputs, targets, straight_angle_frac=0.4,debug=False, drop=False):\n",
    "    \"\"\" Balance dataset for LSTM data \"\"\"\n",
    "    print(\"Balancing data:\")\n",
    "    \n",
    "    # Get distribution \n",
    "    dist = get_dist(inputs, targets)\n",
    "    \n",
    "    inputs_bal = inputs\n",
    "    targets_bal = targets\n",
    "    dist_bal = dist \n",
    "    \n",
    "    # Balance steering angle \n",
    "    print(\"   - Balancing steering angle\")\n",
    "    inputs_bal, targets_bal = balance_steering_angle(inputs_bal, targets_bal, dist_bal, straight_angle_frac)\n",
    "    dist_bal = get_dist(inputs_bal, targets_bal)\n",
    "    \n",
    "\n",
    "    # Shuffle\n",
    "    inputs_bal, targets_bal = shuffle_data(inputs_bal, targets_bal)\n",
    "    \n",
    "    if drop: \n",
    "        inputs_bal, targets_bal = drop_follow_lane(inputs_bal,targets_bal, 3)\n",
    "        \n",
    "    dist_bal = get_dist(inputs_bal, targets_bal)\n",
    "        \n",
    "    return inputs_bal, targets_bal, dist_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop random data \n",
    "Randomly drop data that is follow lane without brake values or turns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_follow_lane(inputs, targets, keep_every): \n",
    "    print(\"Dropping...\")\n",
    "    \n",
    "    inputs_dropped = create_input_dict()\n",
    "    targets_dropped = create_target_dict() \n",
    "    \n",
    "\n",
    "    for i in range(len(inputs[\"forward_imgs\"])): \n",
    "        \n",
    "        \n",
    "        follow_lane = True \n",
    "        # Iterate over all HLC in sequence \n",
    "        for hlc in inputs[\"hlcs\"][i]: \n",
    "            hlc_value = np.argmax(hlc) + 1 \n",
    "            # Only mark sequence as follow lane if all hlcs are follow lane  \n",
    "            if hlc_value != 4:\n",
    "                follow_lane = False \n",
    "                break\n",
    "                \n",
    "        steer = targets[\"steer\"][i]\n",
    "        \n",
    "        # Only drop if FOLLOW_LANE, no brake, and no turn\n",
    "        if follow_lane and abs(steer)<0.1:  \n",
    "            # Drop based on drop_rate \n",
    "            \n",
    "            if np.random.randint(keep_every) != 0: \n",
    "                continue\n",
    "\n",
    "        # Keep \n",
    "        for key in inputs_dropped: \n",
    "            inputs_dropped[key].append(inputs[key][i])\n",
    "        for key in targets_dropped: \n",
    "            targets_dropped[key].append(targets[key][i])\n",
    "\n",
    "    return inputs_dropped, targets_dropped \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode_sequences(data, sampling_interval, seq_length):\n",
    "    sequences = []\n",
    "    slices = []\n",
    "    for o in range(sampling_interval+1):\n",
    "        slices.append(data[o::sampling_interval+1])\n",
    "    for s in slices:\n",
    "        for o in range(0,len(s)):\n",
    "            if o + seq_length <= len(s):\n",
    "                sequences.append(s[o:o+seq_length])\n",
    "    return sequences\n",
    "\n",
    "def prepare_dataset_lstm(inputs, targets, sampling_interval, seq_length):\n",
    "    \n",
    "    inputs_flat = create_input_dict()\n",
    "    targets_flat = create_target_dict()\n",
    "    \n",
    "    for e in range(len(inputs[\"forward_imgs\"])):\n",
    "        [inputs_flat[\"forward_imgs\"].append(sequence) for sequence in get_episode_sequences(inputs[\"forward_imgs\"][e],sampling_interval, seq_length)]\n",
    "        [inputs_flat[\"hlcs\"].append(sequence) for sequence in get_episode_sequences(inputs[\"hlcs\"][e],sampling_interval, seq_length)]\n",
    "        [targets_flat[\"steer\"].append(sequence[-1]) for sequence in get_episode_sequences(targets[\"steer\"][e],sampling_interval, seq_length)]\n",
    "        [targets_flat[\"throttle\"].append(sequence[-1]) for sequence in get_episode_sequences(targets[\"throttle\"][e],sampling_interval, seq_length)]\n",
    "\n",
    "    \n",
    "    # Shuffle\n",
    "    inputs_flat, targets_flat = shuffle_data(inputs_flat, targets_flat)\n",
    "    \n",
    "    return(inputs_flat, targets_flat)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(seq_length, print_summary=True):\n",
    "    forward_image_input = Input(shape=(seq_length, 162, 217, 3), name=\"forward_image_input\")\n",
    "    hlc_input = Input(shape=(seq_length,6), name=\"hlc_input\")\n",
    "\n",
    "    x = TimeDistributed(Cropping2D(cropping=((50,0),(0,0))))(forward_image_input)\n",
    "    x = TimeDistributed(Lambda(lambda x: ((x/255.0) - 0.5)))(x)\n",
    "    x = TimeDistributed(Conv2D(24,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(36,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(48,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3), activation=\"relu\"))(x)\n",
    "    conv_output = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    x = concatenate([conv_output, hlc_input])\n",
    "    \n",
    "    x = TimeDistributed(Dense(100, activation=\"relu\"))(x)\n",
    "    x = CuDNNLSTM(10, return_sequences = False)(x)\n",
    "    steer_pred = Dense(10, activation=\"tanh\", name=\"steer_pred\")(x)\n",
    "    \n",
    "    x = TimeDistributed(Cropping2D(cropping=((50,0),(0,0))))(forward_image_input)\n",
    "    x = TimeDistributed(Lambda(lambda x: ((x/255.0) - 0.5)))(x)\n",
    "    x = TimeDistributed(Conv2D(24,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(36,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(48,(5,5),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3),strides=(2,2), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3), activation=\"relu\"))(x)\n",
    "    x = TimeDistributed(Conv2D(64,(3,3), activation=\"relu\"))(x)\n",
    "    conv_output = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    x = concatenate([conv_output, hlc_input])\n",
    "    \n",
    "    x = TimeDistributed(Dense(100, activation=\"relu\"))(x)\n",
    "    x = CuDNNLSTM(10, return_sequences = False)(x)\n",
    "    throtte_pred = Dense(1, name=\"throttle_pred\")(x)\n",
    "    \n",
    "    model = Model(inputs=[forward_image_input, hlc_input], outputs=[steer_pred,throtte_pred])\n",
    "\n",
    "    if print_summary: \n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(image_path):\n",
    "    return \"./dataset/2019-10-09T11:07:52/episode1/images/\" + image_path.split(\"/\")[-1]\n",
    "\n",
    "print(get_path(\"/home/kia/data_dump/2019-10-09T11:07:52/images/55972.jpg\"))\n",
    "class generator(Sequence):\n",
    "    def __init__(self, inputs, targets, batch_size, validation=False):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.validation = validation \n",
    "        \n",
    "        random.seed() \n",
    "        # Convert to np array\n",
    "        for key in inputs: \n",
    "            inputs[key] = np.array(self.inputs[key])\n",
    "\n",
    "        for key in targets: \n",
    "            targets[key] = np.array(self.targets[key])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.inputs[\"forward_imgs\"]) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subset = np.arange(idx * self.batch_size,min((idx + 1) * self.batch_size,len(self.inputs[\"forward_imgs\"])))\n",
    "        forward_imgs = []\n",
    "        steer_pred = np.array([sine_encode(steer) for steer in self.targets[\"steer\"][subset]])\n",
    "        read_images = [[cv2.resize(cv2.imgread(get_path(path)), fx=0.5, fy=0.5) for path in seq] for seq in self.inputs[\"forward_imgs\"][subset]]\n",
    "        if not self.validation: \n",
    "            augment = 2 #random.randint(0,3)\n",
    "            if augment == 0: \n",
    "                augment_type = random.randint(0,4)\n",
    "                \n",
    "                # Lightness \n",
    "                if augment_type == 0: \n",
    "                    light_coeff = random.random()*0.9+0.5\n",
    "                    for seq in read_images:\n",
    "                        forward_imgs.append([change_light(image, light_coeff=light_coeff) for image in seq])\n",
    "                # Hue \n",
    "                elif augment_type == 1:\n",
    "                    hue_coeff = random.random()*1.4 + 0.2\n",
    "                    for seq in read_images:\n",
    "                        forward_imgs.append([change_hue(image, hue_coeff=hue_coeff) for image in seq])\n",
    "                # Rain \n",
    "                elif augment_type == 2:\n",
    "                    for seq in read_images:\n",
    "                        forward_imgs.append([add_rain(image) for image in seq])\n",
    "                \n",
    "                # Shadows \n",
    "                elif augment_type == 3:\n",
    "                    for seq in read_images:\n",
    "                        forward_imgs.append([add_shadow(image) for image in seq])\n",
    "                # Gaussian blur \n",
    "                elif augment_type == 4:\n",
    "                    for seq in read_images:\n",
    "                        forward_imgs.append([gaussian_blur(image) for image in seq])\n",
    "            else: \n",
    "                for seq in read_images:\n",
    "                    forward_imgs.append([cv2.cvtColor(image,cv2.COLOR_BGR2LAB) for image in seq])\n",
    "        else:\n",
    "            for seq in read_images:\n",
    "                forward_imgs.append([cv2.cvtColor(image,cv2.COLOR_BGR2LAB) for image in seq])\n",
    "\n",
    "        return {\n",
    "            \"forward_image_input\": np.array(forward_imgs), \n",
    "            \"hlc_input\": self.inputs[\"hlcs\"][subset]\n",
    "        }, {\n",
    "            \"steer_pred\": steer_pred,\n",
    "            \"throttle_pred\": self.targets[\"throttle\"][subset],\n",
    "            \"brake_pred\": self.targets[\"brake\"][subset]\n",
    "        }\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"test4_new_autopilot\"\n",
    "val_split = 0.8\n",
    "adjust_hlc = False \n",
    "balance_data = False \n",
    "\n",
    "\n",
    "epochs_list = [15]\n",
    "dataset_folders_lists = [[\"2019-10-09T11:07:52\"]]\n",
    "\"\"\"dataset_folders_lists = [([\n",
    "    \"etron/Town01/ClientAP/no_cars_no_rain\",\n",
    "    \"etron/Town01/ClientAP/no_cars_no_rain_noise15\",\n",
    "    \"etron/Town01/ClientAP/no_cars_rain_noise10\",\n",
    "    \"etron/Town01/ClientAP/cars_no_rain_noise15\",\n",
    "    \"etron/Town01/ClientAP/cars_rain_noise10\",    \n",
    "], [\n",
    "    \"etron/Town04/ClientAP/no_cars_no_rain\", \n",
    "    \"etron/Town04/ClientAP/no_cars_rain_noise5\", \n",
    "    \"etron/Town04/ClientAP/cars_no_rain_noise5\", \n",
    "    \"etron/Town04/ClientAP/cars_rain_noise5\", \n",
    "    \"etron/Town01/ClientAP/brake_all_weather_noise15\",\n",
    "    \"etron/Town01/ClientAP/brake_all_weather\",\n",
    "])]\"\"\"\n",
    "\n",
    "\n",
    "steering_corrections = [0.05]\n",
    "\n",
    "batch_sizes = [32]\n",
    "\n",
    "sampling_interval = [2]\n",
    "\n",
    "seq_length = [10]\n",
    "\n",
    "parameter_permutations = itertools.product(epochs_list, \n",
    "                                           dataset_folders_lists, \n",
    "                                           steering_corrections, \n",
    "                                           batch_sizes,\n",
    "                                           sampling_interval,\n",
    "                                           seq_length)  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train a new model for each parameter permutation, and save the best models\n",
    "model_name = input(\"Name of model test: \").strip()\n",
    "balance_data = True if input(\"Balance data y/[n]: \").lower() == \"y\" else False \n",
    "#drop_data = True if input(\"Drop data y/[n]: \").lower() == \"y\" else False \n",
    "\n",
    "\n",
    "for parameters in parameter_permutations:\n",
    "    \n",
    "    # Get parameters\n",
    "    epochs, dataset_folders, steering_correction, batch_size, sampling_interval, seq_length = parameters\n",
    "    parameters_string = (\"epochs:\\t\\t\\t{}\\ndataset folders:\\t{}\\nsteering correction:\\t{}\\nbatch size:\\t\\t{}\\nsampling interval:\\t{}\\nseq lenght: \\t\\t{}\\n\\n\"\n",
    "                         .format(epochs, str(dataset_folders), steering_correction, batch_size, sampling_interval, seq_length))\n",
    "    \n",
    "    \n",
    "    #town1_dataset_folders, town4_dataset_folders = dataset_folders\n",
    "\n",
    "    # Prepare for logging\n",
    "    timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime(time.time()))\n",
    "    path = Path('models') / model_name / timestamp\n",
    "    if not os.path.exists(str(path)):\n",
    "        os.makedirs(str(path))\n",
    "        \n",
    "    # Save parmeters to disk\n",
    "    with open(str(path / \"parameters.txt\"), \"w\") as text_file:\n",
    "        text_file.write(parameters_string)\n",
    "    \n",
    "    # Save config file to disk \n",
    "    model_name = \"lstm\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config[\"ModelConfig\"] = {'Model': model_name,'sequence_length': seq_length,'sampling_interval': sampling_interval}\n",
    "    with open(str(path/'config.ini'), 'w') as configfile:\n",
    "        config.write(configfile)\n",
    "    \n",
    "    # Load drive logs and paths\n",
    "    #inputs1, targets1 = load_driving_logs(town1_dataset_folders, steering_correction)\n",
    "    #inputs4, targets4 = load_driving_logs(town4_dataset_folders, steering_correction)\n",
    "    inputs, targets = load_driving_logs(dataset_folders, steering_correction)\n",
    "\n",
    "    print(\"Inputs\", inputs)\n",
    "    # Adjust hlcs on town 1 data \n",
    "    #if adjust_hlc: \n",
    "    #    inputs[\"hlcs\"] = inputs(inputs1[\"hlcs\"], inputs[\"info_signals\"])\n",
    "    \n",
    "    # Prepare dataset to model format \n",
    "    #inputs_flat1, targets_flat1 = prepare_dataset_lstm(inputs1, targets1, sampling_interval, seq_length)\n",
    "    #inputs_flat4, targets_flat4 = prepare_dataset_lstm(inputs4, targets4, sampling_interval, seq_length)\n",
    "    inputs_flat, targets_flat = prepare_dataset_lstm(inputs, targets, sampling_interval, seq_length)\n",
    "\n",
    "    # Balance data \n",
    "    if balance_data:\n",
    "        # Plot data before balancing \n",
    "        title_before = \"Before Balancing\"\n",
    "        print(\"inputs_flat\", inputs_flat)\n",
    "        plot_data(get_dist(inputs_flat, targets_flat), title=title_before)\n",
    "\n",
    "        # Balance data \n",
    "        inputs_flat, targets_flat, dist_bal1 = balance_data_lstm(inputs_flat, targets_flat)\n",
    "\n",
    "        # Plot data after balancing \n",
    "        title_after = \"After Balancing\"\n",
    "        plot_data(dist_bal1, title=title_after)\n",
    "\n",
    "\n",
    "    inputs_flat_dict = create_input_dict() \n",
    "    targets_flat_dict = create_target_dict() \n",
    "\n",
    "    for key in inputs_flat: \n",
    "        #inputs_flat[key] = np.concatenate((inputs_flat1[key],inputs_flat4[key]))\n",
    "        inputs_flat_dict[key] = inputs_flat[key] \n",
    "\n",
    "    for key in targets_flat: \n",
    "        targets_flat_dict[key] = targets_flat[key]\n",
    "                \n",
    "    # Shuffle data \n",
    "    inputs_flat, targets_flat = shuffle_data(inputs_flat, targets_flat)\n",
    "    \n",
    "    # Plot final data set \n",
    "    #plot_data(get_dist(inputs_flat), title=\"Final distribution\")\n",
    "           \n",
    "    \n",
    "    # Split into val and train\n",
    "    split_pos = int(val_split*len(inputs_flat[\"forward_imgs\"]))\n",
    "    inputs_train, inputs_val = split_dict(inputs_flat, split_pos)\n",
    "    targets_train, targets_val = split_dict(targets_flat, split_pos)\n",
    "\n",
    "    # Print training info \n",
    "    train_num = len(inputs_train[\"forward_imgs\"])\n",
    "    val_num = len(inputs_val[\"forward_imgs\"])\n",
    "    print(\"Initiate training loop with the following parameters:\")\n",
    "    print(\"---\")\n",
    "    print(parameters_string)\n",
    "    print(\"---\")\n",
    "    print(\"Training set size: \" + str(train_num))\n",
    "    print(\"Validation set size: \" + str(val_num))\n",
    " \n",
    "    # Get model\n",
    "    model = get_lstm_model(seq_length ,print_summary=False)\n",
    "\n",
    "    \n",
    "    # Compile model \n",
    "    model.compile(loss=[steer_loss(), mean_squared_error] , optimizer=Adam())\n",
    "\n",
    "    checkpoint_val = ModelCheckpoint(str(path / ('{epoch:02d}_s{val_steer_pred_loss:.4f}_t{val_throttle_pred_loss:.4f}_b{val_brake_pred_loss:.4f}.h5')), monitor='val_loss', verbose=1, save_best_only=False,mode=\"min\")\n",
    "    \n",
    "    # Create image of model architecture \n",
    "    #plot_model(model, str(path/'model.png'))\n",
    "    \n",
    "    steps = int(train_num/batch_size)\n",
    "    steps_val = int(val_num/batch_size)\n",
    "     \n",
    "    # Train model\n",
    "    history_object = model.fit_generator(\n",
    "        generator(inputs_train, targets_train, batch_size),\n",
    "        validation_data=generator(inputs_val, targets_val, batch_size, validation=True),\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=[checkpoint_val],\n",
    "        steps_per_epoch=steps,\n",
    "        validation_steps = steps_val,\n",
    "        use_multiprocessing = True,\n",
    "        workers=10\n",
    "    )\n",
    "    \n",
    "    # Prepare plot and save it to disk\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    print(\"History\", history_object.history)\n",
    "    ax.plot(history_object.history['steer_pred_loss'], color=\"blue\")\n",
    "    ax.plot(history_object.history['val_steer_pred_loss'], color=\"blue\", linestyle=\"--\")\n",
    "    ax.plot(history_object.history['throttle_pred_loss'], color=\"green\")\n",
    "    ax.plot(history_object.history['val_throttle_pred_loss'], color=\"green\", linestyle=\"--\")\n",
    "    ax.plot(history_object.history['brake_pred_loss'], color=\"red\")\n",
    "    ax.plot(history_object.history['val_brake_pred_loss'], color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_title(\"Mean squared loss of: throttle, brake and steer\")\n",
    "    ax.set_xlabel(\"epochs\")\n",
    "    ax.set_ylabel(\"mse\")\n",
    "\n",
    "    lgd = ax.legend(['steer loss', \n",
    "               'steer validation loss',\n",
    "               'throttle loss', \n",
    "               'throttle validation loss', \n",
    "               'brake loss', \n",
    "               'brake validation loss'], bbox_to_anchor=(1.1, 1.05))\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(str(path / 'loss.png'), bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    print('\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
